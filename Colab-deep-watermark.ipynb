{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-deep-watermark.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdUq5hAtjSuN"
      },
      "source": [
        "# Colab-deep-watermark\n",
        "\n",
        "Original repo: [vinthony/deep-blind-watermark-removal/](https://github.com/vinthony/deep-blind-watermark-removal/)\n",
        "\n",
        "Original colab: [here](https://colab.research.google.com/drive/1pYY7byBjM-7aFIWk8HcF9nK_s6pqGwww?usp=sharing)\n",
        "\n",
        "My fork: [styler00dollar/Colab-deep-watermark](https://github.com/styler00dollar/Colab-deep-watermark)\n",
        "\n",
        "A more userfriendly version of the official colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74agM_f_jMUz"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r73ZJv4bpTVD",
        "cellView": "form"
      },
      "source": [
        "#@title install\n",
        "# download the necessary componments\n",
        "! rm -rf *\n",
        "! git clone https://github.com/vinthony/deep-blind-watermark-removal.git # get code from github\n",
        "! gdown https://drive.google.com/uc?id=1KpSJ6385CHN6WlAINqB3CYrJdleQTJBc # get pretrained model\n",
        "#! gdown https://drive.google.com/uc?id=18HaWfYYZCD34VttSjd2at8b9BKdhgVgU && unzip -q val.zip # get validation dataset (2.31G) of 27kpng\n",
        "#! gdown https://drive.google.com/uc?id=1it5oQDRqRzBVieX6jKNmOxj1992f63yM && unzip -q natural.zip # get natural images (0.4G) of 27kpng\n",
        "\n",
        "# rename natural images\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import shutil\n",
        "#filenames = [ shutil.copy(join('./natural', f), join('./natural', f).split('-')[0]+'.jpg') for f in listdir('./natural') if isfile(join('./natural', f)) ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C_nfkSqifQj"
      },
      "source": [
        "Input ```/content/image.jpg```. Run the following two cells if you change the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "WvOyKxiqffGu"
      },
      "source": [
        "#@title remove folders and copy file\n",
        "!sudo rm -rf /content/val_images/image/\n",
        "!mkdir /content/val_images/image\n",
        "!sudo rm -rf /content/val_images/mask\n",
        "!mkdir /content/val_images/mask\n",
        "!sudo rm -rf /content/val_images/wm\n",
        "!mkdir /content/val_images/wm\n",
        "!sudo rm -rf /content/natural\n",
        "!mkdir /content/natural\n",
        "\n",
        "!sudo rm -rf \"/content/natural/\"\n",
        "!mkdir \"/content/natural/\"\n",
        "!sudo rm -rf \"/content/val_images/\"\n",
        "!mkdir \"/content/val_images/\"\n",
        "!sudo rm -rf \"/content/val_images/image/\"\n",
        "!mkdir \"/content/val_images/image/\"\n",
        "!sudo rm -rf \"/content/val_images/mask/\"\n",
        "!mkdir \"/content/val_images/mask/\"\n",
        "!sudo rm -rf \"/content/val_images/wm/\"\n",
        "!mkdir \"/content/val_images/wm/\"\n",
        "\n",
        "!cp \"/content/image.jpg\" \"/content/natural/image.jpg.jpg\"\n",
        "!cp \"/content/image.jpg\" \"/content/val_images/image/image.jpg\"\n",
        "!cp \"/content/image.jpg\" \"/content/val_images/mask/image.jpg\"\n",
        "!cp \"/content/image.jpg\" \"/content/val_images/wm/image.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iYvIp3kpJpq",
        "cellView": "form"
      },
      "source": [
        "#@title apply\n",
        "import os, sys, torch,random\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "sys.path.append('deep-blind-watermark-removal')\n",
        "sys.path.insert(0,'deep-blind-watermark-removal')\n",
        "\n",
        "from scripts.utils.imutils import im_to_numpy\n",
        "import scripts.models as models\n",
        "import scripts.datasets as datasets\n",
        "%matplotlib inline\n",
        "from PIL import Image, ImageChops\n",
        "\n",
        "def get_jet():\n",
        "    colormap_int = np.zeros((256, 3), np.uint8)\n",
        "\n",
        "    for i in range(0, 256, 1):\n",
        "        colormap_int[i, 0] = np.int_(np.round(cm.jet(i)[0] * 255.0))\n",
        "        colormap_int[i, 1] = np.int_(np.round(cm.jet(i)[1] * 255.0))\n",
        "        colormap_int[i, 2] = np.int_(np.round(cm.jet(i)[2] * 255.0))\n",
        "\n",
        "    return colormap_int\n",
        "\n",
        "def clamp(num, min_value, max_value):\n",
        "    return max(min(num, max_value), min_value)\n",
        "\n",
        "def gray2color(gray_array, color_map):\n",
        "\n",
        "    rows, cols = gray_array.shape\n",
        "    color_array = np.zeros((rows, cols, 3), np.uint8)\n",
        "\n",
        "    for i in range(0, rows):\n",
        "        for j in range(0, cols):\n",
        "#             log(256,2) = 8 , log(1,2) = 0 * 8\n",
        "            color_array[i, j] = color_map[clamp(int(abs(gray_array[i, j])*10),0,255)]\n",
        "\n",
        "    return color_array\n",
        "\n",
        "class objectview(object):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        d = dict(*args, **kwargs)\n",
        "        self.__dict__ = d\n",
        "\n",
        "jet_map = get_jet()\n",
        "\n",
        "resume_path = '27kpng_model_best.pth.tar' # path of pretrained model\n",
        "samples = [320,1364,1868] #random.sample(range(4000), 1) # show random sample\n",
        "\n",
        "data_config  = objectview({'input_size':256,\n",
        "                            'limited_dataset':0,\n",
        "                            'normalized_input':False,\n",
        "                            'data_augumentation':False,\n",
        "                            'base_dir':'.',\n",
        "                            'data':'_images'})\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(datasets.COCO('val',config=data_config))\n",
        "\n",
        "print('input          | target              | coarser            | final')\n",
        "print('----------------------------------------------------------------------------')\n",
        "print('predicted mask | predicted watermark | coarser difference | final difference')\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "      model = models.__dict__['vvv4n']().cuda()\n",
        "      model.load_state_dict(torch.load(resume_path)['state_dict'])\n",
        "      model.eval()\n",
        "\n",
        "      for i, batches in enumerate(val_loader):\n",
        "\n",
        "          plt.figure(figsize=(48,12))\n",
        "\n",
        "          im,mask,target = batches['image'].cuda(),batches['mask'].cuda(),batches['target'].cuda()\n",
        "\n",
        "          imoutput,immask,imwatermark = model(im)\n",
        "\n",
        "          imcoarser,imrefine,imwatermark = imoutput[1]*immask + im*(1-immask),imoutput[0]*immask + im*(1-immask),imwatermark*immask\n",
        "\n",
        "          ims1 = im_to_numpy(torch.clamp(torch.cat([im,target,imcoarser,imrefine],dim=3)[0]*255,min=0.0,max=255.0)).astype(np.uint8)\n",
        "\n",
        "          imcoarser, imrefine, target  = im_to_numpy((imcoarser[0]*255)).astype(np.uint8), im_to_numpy((imrefine[0]*255)).astype(np.uint8), im_to_numpy((target[0]*255)).astype(np.uint8)\n",
        "          immask, imwatermark = im_to_numpy((immask.repeat(1,3,1,1)[0]*255)).astype(np.uint8),im_to_numpy((imwatermark[0]*255)).astype(np.uint8)\n",
        "\n",
        "          coarsenp = gray2color(np.array(ImageChops.difference(Image.fromarray(imcoarser),Image.fromarray(target)).convert('L')),jet_map)\n",
        "          finenp = gray2color(np.array(ImageChops.difference(Image.fromarray(imrefine),Image.fromarray(target)).convert('L')),jet_map)\n",
        "\n",
        "          imfinal = np.concatenate([ims1,np.concatenate([immask,imwatermark,coarsenp,finenp],axis=1)],axis=0)\n",
        "\n",
        "          plt.imshow(imfinal,vmin=0.0,vmax=255.0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exft3vJ7AU8r"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Bx_mIoSLAUR4"
      },
      "source": [
        "#@title install\n",
        "!git clone https://github.com/vinthony/deep-blind-watermark-removal\n",
        "!pip install progress\n",
        "!pip install tensorboardX\n",
        "!pip install pytorch_ssim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "XLmiAjSTAa_8"
      },
      "source": [
        "#@title main.py (forcing coco)\n",
        "%%writefile /content/deep-blind-watermark-removal/main.py\n",
        "from __future__ import print_function, absolute_import\n",
        "\n",
        "import argparse\n",
        "import torch,time,os\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "from scripts.utils.misc import save_checkpoint, adjust_learning_rate\n",
        "\n",
        "import scripts.datasets as datasets\n",
        "import scripts.machines as machines\n",
        "from options import Options\n",
        "\n",
        "def main(args):\n",
        "    \"\"\"\n",
        "    if 'ISTD' in args.base_dir:\n",
        "        dataset_func = datasets.SR\n",
        "    elif 'HFlickr' or 'HCOCO' or 'Hday2night' or 'HAdobe5k' in args.base_dir:\n",
        "        dataset_func = datasets.BIH\n",
        "    else:\n",
        "        dataset_func = datasets.COCO\n",
        "    \"\"\"\n",
        "    # forcing coco\n",
        "    dataset_func = datasets.COCO\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset_func('train',args),batch_size=args.train_batch, shuffle=True,\n",
        "        num_workers=args.workers, pin_memory=True)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(dataset_func('val',args),batch_size=args.test_batch, shuffle=False,\n",
        "        num_workers=args.workers, pin_memory=True)\n",
        "\n",
        "    lr = args.lr\n",
        "    data_loaders = (train_loader,val_loader)\n",
        "\n",
        "    Machine = machines.__dict__[args.machine](datasets=data_loaders, args=args)\n",
        "    print('============================ Initization Finish && Training Start =============================================')\n",
        "\n",
        "    for epoch in range(Machine.args.start_epoch, Machine.args.epochs):\n",
        "\n",
        "        print('\\nEpoch: %d | LR: %.8f' % (epoch + 1, lr))\n",
        "        lr = adjust_learning_rate(data_loaders, Machine.optimizer, epoch, lr, args)\n",
        "\n",
        "        Machine.record('lr',lr, epoch)\n",
        "        Machine.train(epoch)\n",
        "\n",
        "        if args.freq < 0:\n",
        "            Machine.validate(epoch)\n",
        "            Machine.flush()\n",
        "            Machine.save_checkpoint()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser=Options().init(argparse.ArgumentParser(description='WaterMark Removal'))\n",
        "    args = parser.parse_args()\n",
        "    print('==================================== WaterMark Removal =============================================')\n",
        "    print('==> {:50}: {:<}'.format(\"Start Time\",time.ctime(time.time())))\n",
        "    print('==> {:50}: {:<}'.format(\"USE GPU\",os.environ['CUDA_VISIBLE_DEVICES']))\n",
        "    print('==================================== Stable Parameters =============================================')\n",
        "    for arg in vars(args):\n",
        "        if type(getattr(args, arg)) == type([]):\n",
        "            if ','.join([ str(i) for i in getattr(args, arg)]) == ','.join([ str(i) for i in parser.get_default(arg)]):\n",
        "                print('==> {:50}: {:<}({:<})'.format(arg,','.join([ str(i) for i in getattr(args, arg)]),','.join([ str(i) for i in parser.get_default(arg)])))\n",
        "        else:\n",
        "            if getattr(args, arg) == parser.get_default(arg):\n",
        "                print('==> {:50}: {:<}({:<})'.format(arg,getattr(args, arg),parser.get_default(arg)))\n",
        "    print('==================================== Changed Parameters =============================================')\n",
        "    for arg in vars(args):\n",
        "        if type(getattr(args, arg)) == type([]):\n",
        "            if ','.join([ str(i) for i in getattr(args, arg)]) != ','.join([ str(i) for i in parser.get_default(arg)]):\n",
        "                print('==> {:50}: {:<}({:<})'.format(arg,','.join([ str(i) for i in getattr(args, arg)]),','.join([ str(i) for i in parser.get_default(arg)])))\n",
        "        else:\n",
        "            if getattr(args, arg) != parser.get_default(arg):\n",
        "                print('==> {:50}: {:<}({:<})'.format(arg,getattr(args, arg),parser.get_default(arg)))\n",
        "    print('==================================== Start Init Model  ===============================================')\n",
        "    main(args)\n",
        "    print('==================================== FINISH WITHOUT ERROR =============================================')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "WcFVTkydAc0q"
      },
      "source": [
        "#@title COCO.py (setting my_path)\n",
        "%%writefile /content/deep-blind-watermark-removal/scripts/datasets/COCO.py\n",
        "from __future__ import print_function, absolute_import\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "from scripts.utils.osutils import *\n",
        "from scripts.utils.imutils import *\n",
        "from scripts.utils.transforms import *\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from PIL import ImageEnhance\n",
        "from PIL import ImageFilter\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "class COCO(data.Dataset):\n",
        "    def __init__(self,train,config=None, sample=[],gan_norm=False):\n",
        "\n",
        "        self.train = []\n",
        "        self.anno = []\n",
        "        self.mask = []\n",
        "        self.wm = []\n",
        "        self.input_size = config.input_size\n",
        "        self.normalized_input = config.normalized_input\n",
        "        self.base_folder = config.base_dir\n",
        "        self.dataset = train+config.data\n",
        "\n",
        "        if config == None:\n",
        "            self.data_augumentation = False\n",
        "        else:\n",
        "            self.data_augumentation = config.data_augumentation\n",
        "\n",
        "        self.istrain = False if self.dataset.find('train') == -1 else True\n",
        "        self.sample = sample\n",
        "        self.gan_norm = gan_norm\n",
        "        #mypath = join(self.base_folder,self.dataset)\n",
        "        mypath = '/content/data/'\n",
        "        file_names = sorted([f for f in listdir(join(mypath,'image')) if isfile(join(mypath,'image', f)) ])\n",
        "\n",
        "        if config.limited_dataset > 0:\n",
        "            xtrain = sorted(list(set([ file_name.split('-')[0] for file_name in file_names ])))\n",
        "            tmp = []\n",
        "            for x in xtrain:\n",
        "                # get the file_name by identifier\n",
        "                tmp.append([y for y in file_names if x in y][0])\n",
        "\n",
        "            file_names = tmp\n",
        "        else:\n",
        "            file_names = file_names\n",
        "\n",
        "        for file_name in file_names:\n",
        "            self.train.append(os.path.join(mypath,'image',file_name)) # watermarked\n",
        "            self.mask.append(os.path.join(mypath,'mask',file_name))\n",
        "            self.wm.append(os.path.join(mypath,'wm',file_name))\n",
        "            #self.anno.append(os.path.join(self.base_folder,'natural',file_name.split('-')[0]+'.jpg'))\n",
        "            self.anno.append(os.path.join(mypath,'natural',file_name)) # not watermarked\n",
        "\n",
        "        if len(self.sample) > 0 :\n",
        "            self.train = [ self.train[i] for i in self.sample ]\n",
        "            self.mask = [ self.mask[i] for i in self.sample ]\n",
        "            self.anno = [ self.anno[i] for i in self.sample ]\n",
        "\n",
        "        self.trans = transforms.Compose([\n",
        "                transforms.Resize((self.input_size,self.input_size)),\n",
        "                transforms.ToTensor()\n",
        "            ])\n",
        "\n",
        "        print('total Dataset of '+self.dataset+' is : ', len(self.train))\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.train[index]).convert('RGB')\n",
        "        mask = Image.open(self.mask[index]).convert('L')\n",
        "        anno = Image.open(self.anno[index]).convert('RGB')\n",
        "        wm = Image.open(self.wm[index]).convert('RGB')\n",
        "\n",
        "\n",
        "        return {\"image\": self.trans(img),\n",
        "                \"target\": self.trans(anno),\n",
        "                \"mask\": self.trans(mask),\n",
        "                \"wm\": self.trans(wm),\n",
        "                \"name\": self.train[index].split('/')[-1],\n",
        "                \"imgurl\":self.train[index],\n",
        "                \"maskurl\":self.mask[index],\n",
        "                \"targeturl\":self.anno[index],\n",
        "                \"wmurl\":self.wm[index]\n",
        "                }\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "GQIf7ZrpAwIe"
      },
      "source": [
        "#@title VX.py (deleting ssim, png eval)\n",
        "%%writefile /content/deep-blind-watermark-removal/scripts/machines/VX.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from progress.bar import Bar\n",
        "from tqdm import tqdm\n",
        "import pytorch_ssim\n",
        "import json\n",
        "import sys,time,os\n",
        "import torchvision\n",
        "from math import log10\n",
        "import numpy as np\n",
        "from .BasicMachine import BasicMachine\n",
        "from scripts.utils.evaluation import accuracy, AverageMeter, final_preds\n",
        "from scripts.utils.misc import resize_to_match\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from scripts.utils.parallel import DataParallelModel, DataParallelCriterion\n",
        "from scripts.utils.losses import VGGLoss, l1_relative,is_dic\n",
        "from scripts.utils.imutils import im_to_numpy\n",
        "import skimage.io\n",
        "from skimage.measure import compare_psnr,compare_ssim\n",
        "\n",
        "\n",
        "class Losses(nn.Module):\n",
        "    def __init__(self, argx, device, norm_func=None, denorm_func=None):\n",
        "        super(Losses, self).__init__()\n",
        "        self.args = argx\n",
        "\n",
        "        if self.args.loss_type == 'l1bl2':\n",
        "            self.outputLoss, self.attLoss, self.wrloss = nn.L1Loss(), nn.BCELoss(), nn.MSELoss()\n",
        "        elif self.args.loss_type == 'l2xbl2':\n",
        "            self.outputLoss, self.attLoss, self.wrloss = nn.MSELoss(), nn.BCEWithLogitsLoss(), nn.MSELoss()\n",
        "        elif self.args.loss_type == 'relative' or self.args.loss_type == 'hybrid':\n",
        "            self.outputLoss, self.attLoss, self.wrloss = l1_relative, nn.BCELoss(), l1_relative\n",
        "        else: # l2bl2\n",
        "            self.outputLoss, self.attLoss, self.wrloss = nn.MSELoss(), nn.BCELoss(), nn.MSELoss()\n",
        "\n",
        "        self.default = nn.L1Loss()\n",
        "\n",
        "        if self.args.style_loss > 0:\n",
        "            self.vggloss = VGGLoss(self.args.sltype).to(device)\n",
        "\n",
        "        if self.args.ssim_loss > 0:\n",
        "            self.ssimloss =  pytorch_ssim.SSIM().to(device)\n",
        "\n",
        "        self.norm = norm_func\n",
        "        self.denorm = denorm_func\n",
        "\n",
        "\n",
        "    def forward(self,pred_ims,target,pred_ms,mask,pred_wms,wm):\n",
        "        pixel_loss,att_loss,wm_loss,vgg_loss,ssim_loss = [0]*5\n",
        "        pred_ims = pred_ims if is_dic(pred_ims) else [pred_ims]\n",
        "\n",
        "        # try the loss in the masked region\n",
        "        if self.args.masked and 'hybrid' in self.args.loss_type: # masked loss\n",
        "            pixel_loss += sum([self.outputLoss(pred_im, target, mask) for pred_im in pred_ims])\n",
        "            pixel_loss += sum([self.default(pred_im*pred_ms,target*mask) for pred_im in pred_ims])\n",
        "            recov_imgs = [ self.denorm(pred_im*mask + (1-mask)*self.norm(target)) for pred_im in pred_ims ]\n",
        "            wm_loss += self.wrloss(pred_wms, wm, mask)\n",
        "            wm_loss += self.default(pred_wms*pred_ms, wm*mask)\n",
        "\n",
        "        elif self.args.masked and 'relative' in self.args.loss_type: # masked loss\n",
        "            pixel_loss += sum([self.outputLoss(pred_im, target, mask) for pred_im in pred_ims])\n",
        "            recov_imgs = [ self.denorm(pred_im*mask + (1-mask)*self.norm(target)) for pred_im in pred_ims ]\n",
        "            wm_loss = self.wrloss(pred_wms, wm, mask)\n",
        "        elif self.args.masked:\n",
        "            pixel_loss += sum([self.outputLoss(pred_im*mask, target*mask) for pred_im in pred_ims])\n",
        "            recov_imgs = [ self.denorm(pred_im*pred_ms + (1-pred_ms)*self.norm(target)) for pred_im in pred_ims ]\n",
        "            wm_loss = self.wrloss(pred_wms*mask, wm*mask)\n",
        "        else:\n",
        "            pixel_loss += sum([self.outputLoss(pred_im*pred_ms, target*mask) for pred_im in pred_ims])\n",
        "            recov_imgs = [ self.denorm(pred_im*pred_ms + (1-pred_ms)*self.norm(target)) for pred_im in pred_ims ]\n",
        "            wm_loss = self.wrloss(pred_wms*pred_ms,wm*mask)\n",
        "\n",
        "        pixel_loss += sum([self.default(im,target) for im in recov_imgs])\n",
        "\n",
        "        if self.args.style_loss > 0:\n",
        "            vgg_loss = sum([self.vggloss(im,target,mask) for im in recov_imgs])\n",
        "\n",
        "        #if self.args.ssim_loss > 0:\n",
        "        #    ssim_loss = sum([ 1 - self.ssimloss(im,target) for im in recov_imgs])\n",
        "        ssim_loss = [0]\n",
        "\n",
        "        att_loss =  self.attLoss(pred_ms, mask)\n",
        "\n",
        "        return pixel_loss,att_loss,wm_loss,vgg_loss,ssim_loss\n",
        "\n",
        "\n",
        "class VX(BasicMachine):\n",
        "    def __init__(self,**kwargs):\n",
        "        BasicMachine.__init__(self,**kwargs)\n",
        "        self.loss = Losses(self.args, self.device, self.norm, self.denorm)\n",
        "        self.model.set_optimizers()\n",
        "        self.optimizer = None\n",
        "\n",
        "    def train(self,epoch):\n",
        "\n",
        "        self.current_epoch = epoch\n",
        "\n",
        "        batch_time = AverageMeter()\n",
        "        data_time = AverageMeter()\n",
        "        losses = AverageMeter()\n",
        "        lossMask = AverageMeter()\n",
        "        lossWM = AverageMeter()\n",
        "        lossMX = AverageMeter()\n",
        "        lossvgg = AverageMeter()\n",
        "        lossssim = AverageMeter()\n",
        "\n",
        "        # switch to train mode\n",
        "        self.model.train()\n",
        "\n",
        "        end = time.time()\n",
        "        bar = Bar('Processing {} '.format(self.args.arch), max=len(self.train_loader))\n",
        "\n",
        "        for i, batches in enumerate(self.train_loader):\n",
        "\n",
        "            current_index = len(self.train_loader) * epoch + i\n",
        "\n",
        "            inputs = batches['image'].to(self.device)\n",
        "            target = batches['target'].to(self.device)\n",
        "            mask = batches['mask'].to(self.device)\n",
        "            #print(batches)\n",
        "            wm =  batches['wm'].to(self.device)\n",
        "\n",
        "            outputs = self.model(self.norm(inputs))\n",
        "\n",
        "            self.model.zero_grad_all()\n",
        "\n",
        "            l2_loss,att_loss,wm_loss,style_loss,ssim_loss = self.loss(outputs[0],self.norm(target),outputs[1],mask,outputs[2],self.norm(wm))\n",
        "            #total_loss = 2*l2_loss + self.args.att_loss * att_loss + wm_loss + self.args.style_loss * style_loss + self.args.ssim_loss * ssim_loss\n",
        "            total_loss = 2*l2_loss + self.args.att_loss * att_loss + wm_loss + self.args.style_loss * style_loss\n",
        "\n",
        "            # compute gradient and do SGD step\n",
        "            total_loss.backward()\n",
        "            self.model.step_all()\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            losses.update(l2_loss.item(), inputs.size(0))\n",
        "            lossMask.update(att_loss.item(), inputs.size(0))\n",
        "            lossWM.update(wm_loss.item(), inputs.size(0))\n",
        "\n",
        "            if self.args.style_loss > 0 :\n",
        "                lossvgg.update(style_loss.item(), inputs.size(0))\n",
        "\n",
        "            #if self.args.ssim_loss > 0 :\n",
        "            #    lossssim.update(ssim_loss.item(), inputs.size(0))\n",
        "\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            # plot progress\n",
        "            suffix  = \"({batch}/{size}) Data: {data:.2f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss L2: {loss_label:.4f} | Loss Mask: {loss_mask:.4f} | loss WM: {loss_wm:.4f} | loss VGG: {loss_vgg:.4f} | loss SSIM: {loss_ssim:.4f}| loss MX: {loss_mx:.4f}\".format(\n",
        "                        batch=i + 1,\n",
        "                        size=len(self.train_loader),\n",
        "                        data=data_time.val,\n",
        "                        bt=batch_time.val,\n",
        "                        total=bar.elapsed_td,\n",
        "                        eta=bar.eta_td,\n",
        "                        loss_label=losses.avg,\n",
        "                        loss_mask=lossMask.avg,\n",
        "                        loss_wm=lossWM.avg,\n",
        "                        loss_vgg=lossvgg.avg,\n",
        "                        loss_ssim=lossssim.avg,\n",
        "                        loss_mx=lossMX.avg\n",
        "                        )\n",
        "            if current_index % 1000 == 0:\n",
        "                print(suffix)\n",
        "\n",
        "            if self.args.freq > 0 and current_index % self.args.freq == 0:\n",
        "                self.validate(current_index)\n",
        "                self.flush()\n",
        "                self.save_checkpoint()\n",
        "\n",
        "        self.record('train/loss_L2', losses.avg, epoch)\n",
        "        self.record('train/loss_Mask', lossMask.avg, epoch)\n",
        "        self.record('train/loss_WM', lossWM.avg, epoch)\n",
        "        self.record('train/loss_VGG', lossvgg.avg, epoch)\n",
        "        self.record('train/loss_SSIM', lossssim.avg, epoch)\n",
        "        self.record('train/loss_MX', lossMX.avg, epoch)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def validate(self, epoch):\n",
        "\n",
        "        self.current_epoch = epoch\n",
        "\n",
        "        batch_time = AverageMeter()\n",
        "        data_time = AverageMeter()\n",
        "        losses = AverageMeter()\n",
        "        lossMask = AverageMeter()\n",
        "        psnres = AverageMeter()\n",
        "        ssimes = AverageMeter()\n",
        "\n",
        "        # switch to evaluate mode\n",
        "        self.model.eval()\n",
        "\n",
        "        end = time.time()\n",
        "        bar = Bar('Processing {} '.format(self.args.arch), max=len(self.val_loader))\n",
        "        with torch.no_grad():\n",
        "            for i, batches in enumerate(self.val_loader):\n",
        "\n",
        "                current_index = len(self.val_loader) * epoch + i\n",
        "\n",
        "                inputs = batches['image'].to(self.device)\n",
        "                target = batches['target'].to(self.device)\n",
        "\n",
        "                outputs = self.model(self.norm(inputs))\n",
        "                imoutput,immask,imwatermark = outputs\n",
        "                imoutput = imoutput[0] if is_dic(imoutput) else imoutput\n",
        "\n",
        "                imfinal = self.denorm(imoutput*immask + self.norm(inputs)*(1-immask))\n",
        "\n",
        "                if i % 300 == 0:\n",
        "                    # save the sample images\n",
        "                    ims = torch.cat([inputs,target,imfinal,immask.repeat(1,3,1,1)],dim=3)\n",
        "                    torchvision.utils.save_image(ims,os.path.join(self.args.checkpoint,'%s_%s.png'%(i,epoch)))\n",
        "\n",
        "                # here two choice: mseLoss or NLLLoss\n",
        "                psnr = 10 * log10(1 / F.mse_loss(imfinal,target).item())\n",
        "\n",
        "                #ssim = pytorch_ssim.ssim(imfinal,target)\n",
        "\n",
        "                psnres.update(psnr, inputs.size(0))\n",
        "                #ssimes.update(ssim, inputs.size(0))\n",
        "\n",
        "                # measure elapsed time\n",
        "                batch_time.update(time.time() - end)\n",
        "                end = time.time()\n",
        "\n",
        "                # plot progress\n",
        "                bar.suffix  = '({batch}/{size}) Data: {data:.2f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss_L2: {loss_label:.4f} | Loss_Mask: {loss_mask:.4f} | PSNR: {psnr:.4f} | SSIM: {ssim:.4f}'.format(\n",
        "                            batch=i + 1,\n",
        "                            size=len(self.val_loader),\n",
        "                            data=data_time.val,\n",
        "                            bt=batch_time.val,\n",
        "                            total=bar.elapsed_td,\n",
        "                            eta=bar.eta_td,\n",
        "                            loss_label=losses.avg,\n",
        "                            loss_mask=lossMask.avg,\n",
        "                            psnr=psnres.avg,\n",
        "                            ssim=ssimes.avg\n",
        "                            )\n",
        "                bar.next()\n",
        "        bar.finish()\n",
        "\n",
        "        print(\"Iter:%s,Losses:%s,PSNR:%.4f,SSIM:%.4f\"%(epoch, losses.avg,psnres.avg,ssimes.avg))\n",
        "        self.record('val/loss_L2', losses.avg, epoch)\n",
        "        self.record('val/lossMask', lossMask.avg, epoch)\n",
        "        self.record('val/PSNR', psnres.avg, epoch)\n",
        "        self.record('val/SSIM', ssimes.avg, epoch)\n",
        "        self.metric = psnres.avg\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "    def test(self, ):\n",
        "\n",
        "        # switch to evaluate mode\n",
        "        self.model.eval()\n",
        "        print(\"==> testing VM model \")\n",
        "        ssimes = AverageMeter()\n",
        "        psnres = AverageMeter()\n",
        "        ssimesx = AverageMeter()\n",
        "        psnresx = AverageMeter()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, batches in enumerate(tqdm(self.val_loader)):\n",
        "\n",
        "                inputs = batches['image'].to(self.device)\n",
        "                target = batches['target'].to(self.device)\n",
        "                mask =batches['mask'].to(self.device)\n",
        "\n",
        "                # select the outputs by the giving arch\n",
        "                outputs = self.model(self.norm(inputs))\n",
        "                imoutput,immask,imwatermark = outputs\n",
        "                imoutput = imoutput[0] if is_dic(imoutput) else imoutput\n",
        "\n",
        "                imfinal = self.denorm(imoutput*immask + self.norm(inputs)*(1-immask))\n",
        "                psnrx = 10 * log10(1 / F.mse_loss(imfinal,target).item())\n",
        "                ssimx = pytorch_ssim.ssim(imfinal,target)\n",
        "                # recover the image to 255\n",
        "                imfinal = im_to_numpy(torch.clamp(imfinal[0]*255,min=0.0,max=255.0)).astype(np.uint8)\n",
        "                target = im_to_numpy(torch.clamp(target[0]*255,min=0.0,max=255.0)).astype(np.uint8)\n",
        "\n",
        "                skimage.io.imsave('%s/%s'%(self.args.checkpoint,batches['name'][0]), imfinal)\n",
        "\n",
        "                psnr = compare_psnr(target,imfinal)\n",
        "                ssim = compare_ssim(target,imfinal,multichannel=True)\n",
        "\n",
        "                psnres.update(psnr, inputs.size(0))\n",
        "                ssimes.update(ssim, inputs.size(0))\n",
        "                psnresx.update(psnrx, inputs.size(0))\n",
        "                ssimesx.update(ssimx, inputs.size(0))\n",
        "\n",
        "        print(\"%s:PSNR:%.5f(%.5f),SSIM:%.5f(%.5f)\"%(self.args.checkpoint,psnres.avg,psnresx.avg,ssimes.avg,ssimesx.avg))\n",
        "        print(\"DONE.\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT7_fxXSAgqi"
      },
      "source": [
        "Data structure\n",
        "```\n",
        "/content/data/image/000.png (Masked image (RGBA32)\n",
        "/content/data/mask/000.png (Mask where watermark is (white is mask) (GRAY8BPP))\n",
        "/content/data/natural/000.png (Original image (RGB/YUV)\n",
        "/content/data/wm/000.png (Watermark (RGBA32))\n",
        "\n",
        "/content/data/image_train.txt (List of filenames of /image folder)\n",
        "/content/data/image_val.txt (List of filenames of /natural folder)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ATC3VzO-Afla"
      },
      "source": [
        "#@title create folders\n",
        "!mkdir /content/data\n",
        "!mkdir /content/data/image\n",
        "!mkdir /content/data/mask\n",
        "!mkdir /content/data/wm\n",
        "!mkdir /content/data/natural\n",
        "!mkdir /content/eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuKsZXBFAsPg"
      },
      "source": [
        "Create files with filenames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dxmTfbFAriP"
      },
      "source": [
        "%%writefile /content/data/image_train.txt\n",
        "/content/data/image/000.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrSXkMwVAt3J"
      },
      "source": [
        "%%writefile /content/data/image_val.txt\n",
        "/content/data/natural/000.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "kxPZYk2GA1r7"
      },
      "source": [
        "#@title train\n",
        "!CUDA_VISIBLE_DEVICES=0 python /content/deep-blind-watermark-removal/main.py \\\n",
        " --epochs 100\\\n",
        " --schedule 100\\\n",
        " --lr 1e-3\\\n",
        " -c /content/eval/ \\\n",
        " --arch vvv4n\\\n",
        " --sltype vggx\\\n",
        " --style-loss 0.025\\\n",
        " --ssim-loss 0.15\\\n",
        " --masked True\\\n",
        " --loss-type hybrid\\\n",
        " --limited-dataset 1\\\n",
        " --machine vx\\\n",
        " --input-size 256\\\n",
        " --train-batch 1\\\n",
        " --test-batch 1\\\n",
        " --base-dir /content/ \\\n",
        " --data /content/data/image"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}